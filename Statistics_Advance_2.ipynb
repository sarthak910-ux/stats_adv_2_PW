{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Practical Answers"
      ],
      "metadata": {
        "id": "zEdeSGQw2jEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample, population_mean, population_std, alpha=0.05):\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Compute the p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpret the results\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population means.\")\n",
        "\n",
        "# Example usage\n",
        "sample_data = [50, 52, 48, 49, 51, 53, 50, 52, 49, 50]\n",
        "pop_mean = 50\n",
        "pop_std = 2\n",
        "z_test(sample_data, pop_mean, pop_std)\n"
      ],
      "metadata": {
        "id": "v3a72kKy2mfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample, population_mean, population_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "    :param sample: List or NumPy array of sample data.\n",
        "    :param population_mean: Known population mean.\n",
        "    :param population_std: Known population standard deviation.\n",
        "    :param alpha: Significance level (default is 0.05).\n",
        "    \"\"\"\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Compute the p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpret the results\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population means.\")\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=2, size=30)  # Mean=50, Std=2, Sample size=30\n",
        "pop_mean = 50\n",
        "pop_std = 2\n",
        "\n",
        "# Perform hypothesis testing\n",
        "z_test(sample_data, pop_mean, pop_std)\n"
      ],
      "metadata": {
        "id": "utW36qwW3IT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample, population_mean, population_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    :param sample: List or NumPy array of sample data.\n",
        "    :param population_mean: Known population mean.\n",
        "    :param population_std: Known population standard deviation.\n",
        "    :param alpha: Significance level (default is 0.05).\n",
        "    \"\"\"\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Compute the p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpret the results\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population means.\")\n",
        "\n",
        "# Example usage\n",
        "sample_data = [50, 52, 48, 49, 51, 53, 50, 52, 49, 50]\n",
        "pop_mean = 50\n",
        "pop_std = 2\n",
        "z_test(sample_data, pop_mean, pop_std)"
      ],
      "metadata": {
        "id": "kFZGI6Db3yxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def two_tailed_z_test(sample, population_mean, population_std, alpha=0.05):\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_size = len(sample)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Compute the p-value\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpret the results\n",
        "    print(f\"Sample Mean: {sample_mean}\")\n",
        "    print(f\"Z-Score: {z_score}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis: No significant difference between the sample and population means.\")\n",
        "\n",
        "    # Visualize the decision region\n",
        "    x = np.linspace(population_mean - 4 * population_std, population_mean + 4 * population_std, 100)\n",
        "    y = stats.norm.pdf(x, population_mean, population_std)\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.fill_between(x, y, where=(x < population_mean - stats.norm.ppf(1 - alpha / 2) * population_std) |\n",
        "                             (x > population_mean + stats.norm.ppf(1 - alpha / 2) * population_std),\n",
        "                     color='red', alpha=0.5)\n",
        "    plt.axvline(sample_mean, color='green', linestyle='--', label='Sample Mean')\n",
        "    plt.title('Two-Tailed Z-Test Decision Region')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "sample_data = [50, 52, 48, 49, 51, 53, 50, 52, 49, 50]\n",
        "pop_mean = 50\n",
        "pop_std = 2\n",
        "two_tailed_z_test(sample_data, pop_mean, pop_std)"
      ],
      "metadata": {
        "id": "8KkO7zeV4Lzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_hypothesis_testing(mu_0=0, sigma_0=1, mu_1=2, sigma_1=1, alpha=0.05):\n",
        "    # Critical value (right-tailed test for simplicity)\n",
        "    critical_value = norm.ppf(1 - alpha, loc=mu_0, scale=sigma_0)\n",
        "\n",
        "    # Compute Type 2 error (Beta)\n",
        "    beta = norm.cdf(critical_value, loc=mu_1, scale=sigma_1)\n",
        "    power = 1 - beta  # Power of the test\n",
        "\n",
        "    # X values for plotting\n",
        "    x = np.linspace(mu_0 - 4 * sigma_0, mu_1 + 4 * sigma_1, 1000)\n",
        "\n",
        "    # Probability densities\n",
        "    pdf_0 = norm.pdf(x, loc=mu_0, scale=sigma_0)  # H0 distribution\n",
        "    pdf_1 = norm.pdf(x, loc=mu_1, scale=sigma_1)  # H1 distribution\n",
        "\n",
        "    # Plot distributions\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf_0, label=\"H0 (Null Hypothesis)\", color=\"blue\")\n",
        "    plt.plot(x, pdf_1, label=\"H1 (Alternative Hypothesis)\", color=\"red\")\n",
        "\n",
        "    # Fill Type 1 error region (False Positive)\n",
        "    plt.fill_between(x, pdf_0, where=(x >= critical_value), color=\"blue\", alpha=0.3, label=\"Type 1 Error (α)\")\n",
        "\n",
        "    # Fill Type 2 error region (False Negative)\n",
        "    plt.fill_between(x, pdf_1, where=(x < critical_value), color=\"red\", alpha=0.3, label=\"Type 2 Error (β)\")\n",
        "\n",
        "    # Vertical line at critical value\n",
        "    plt.axvline(critical_value, color=\"black\", linestyle=\"dashed\", label=f\"Critical Value = {critical_value:.2f}\")\n",
        "\n",
        "    # Labels and legend\n",
        "    plt.xlabel(\"Test Statistic\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.title(f\"Hypothesis Testing: Type 1 and Type 2 Errors (Power = {power:.2f})\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "visualize_hypothesis_testing()\n"
      ],
      "metadata": {
        "id": "hBbEoUBn4ZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def independent_t_test(data1=None, data2=None, alpha=0.05):\n",
        "    # Generate random data if none is provided\n",
        "    if data1 is None:\n",
        "        data1 = np.random.normal(loc=50, scale=10, size=30)  # Mean=50, Std=10, n=30\n",
        "    if data2 is None:\n",
        "        data2 = np.random.normal(loc=55, scale=10, size=30)  # Mean=55, Std=10, n=30\n",
        "\n",
        "    # Check variance equality using Levene’s test\n",
        "    stat_var, p_var = stats.levene(data1, data2)\n",
        "    equal_var = p_var > alpha  # If p > alpha, assume equal variance\n",
        "\n",
        "    # Perform independent T-test\n",
        "    t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=equal_var)\n",
        "\n",
        "    # Effect size (Cohen's d)\n",
        "    pooled_std = np.sqrt(((len(data1) - 1) * np.var(data1, ddof=1) +\n",
        "                          (len(data2) - 1) * np.var(data2, ddof=1)) /\n",
        "                         (len(data1) + len(data2) - 2))\n",
        "    cohen_d = (np.mean(data1) - np.mean(data2)) / pooled_std\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n--- Independent T-Test Results ---\")\n",
        "    print(f\"Mean of Group 1: {np.mean(data1):.2f}, Mean of Group 2: {np.mean(data2):.2f}\")\n",
        "    print(f\"T-statistic: {t_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "    print(f\"Assuming Equal Variance: {equal_var}\")\n",
        "    print(f\"Cohen's d (Effect Size): {cohen_d:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        print(f\"The difference is statistically significant (p < {alpha}). Reject H0.\")\n",
        "    else:\n",
        "        print(f\"No significant difference found (p >= {alpha}). Fail to reject H0.\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(data1, alpha=0.6, bins=10, label=\"Group 1\", color=\"blue\", edgecolor=\"black\")\n",
        "    plt.hist(data2, alpha=0.6, bins=10, label=\"Group 2\", color=\"red\", edgecolor=\"black\")\n",
        "    plt.axvline(np.mean(data1), color=\"blue\", linestyle=\"dashed\", label=f\"Mean 1 = {np.mean(data1):.2f}\")\n",
        "    plt.axvline(np.mean(data2), color=\"red\", linestyle=\"dashed\", label=f\"Mean 2 = {np.mean(data2):.2f}\")\n",
        "    plt.xlabel(\"Values\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Distribution of Two Independent Samples\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "independent_t_test()\n"
      ],
      "metadata": {
        "id": "liR2sG5S4xQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def paired_t_test(data1=None, data2=None, alpha=0.05):\n",
        "    # Generate random paired data if not provided\n",
        "    if data1 is None or data2 is None:\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "        data1 = np.random.normal(50, 10, 30)  # Baseline\n",
        "        data2 = data1 + np.random.normal(3, 5, 30)  # Treatment effect\n",
        "\n",
        "    # Perform Paired T-test\n",
        "    t_stat, p_value = stats.ttest_rel(data1, data2)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n--- Paired T-Test Results ---\")\n",
        "    print(f\"Mean of Before: {np.mean(data1):.2f}, Mean of After: {np.mean(data2):.2f}\")\n",
        "    print(f\"T-statistic: {t_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        print(f\"The difference is statistically significant (p < {alpha}). Reject H0.\")\n",
        "    else:\n",
        "        print(f\"No significant difference found (p >= {alpha}). Fail to reject H0.\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(data1, data2, 'o', markersize=6, alpha=0.7)\n",
        "    plt.plot([min(data1), max(data1)], [min(data1), max(data1)], linestyle=\"dashed\", color=\"gray\")  # Diagonal Line\n",
        "    plt.xlabel(\"Before (Pre-Test)\")\n",
        "    plt.ylabel(\"After (Post-Test)\")\n",
        "    plt.title(\"Paired Sample Comparison\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "paired_t_test()\n"
      ],
      "metadata": {
        "id": "h73rb8615DSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test_t_test(n=25, mu=50, sigma=10, mu_pop=52, alpha=0.05):\n",
        "    np.random.seed(42)  # Reproducibility\n",
        "    sample = np.random.normal(mu, sigma, n)  # Simulate data\n",
        "\n",
        "    # Compute sample statistics\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # Sample standard deviation\n",
        "\n",
        "    # Perform Z-test (assume known population std dev)\n",
        "    z_stat = (sample_mean - mu_pop) / (sigma / np.sqrt(n))\n",
        "    p_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Perform T-test\n",
        "    t_stat, p_t = stats.ttest_1samp(sample, mu_pop)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n--- Test Results ---\")\n",
        "    print(f\"Sample Mean: {sample_mean:.2f}, Population Mean: {mu_pop}\")\n",
        "    print(f\"Z-Test: Z-statistic = {z_stat:.4f}, P-value = {p_z:.4f}\")\n",
        "    print(f\"T-Test: T-statistic = {t_stat:.4f}, P-value = {p_t:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    if p_z < alpha:\n",
        "        print(\"Z-test: Significant difference detected (Reject H0)\")\n",
        "    else:\n",
        "        print(\"Z-test: No significant difference (Fail to reject H0)\")\n",
        "\n",
        "    if p_t < alpha:\n",
        "        print(\"T-test: Significant difference detected (Reject H0)\")\n",
        "    else:\n",
        "        print(\"T-test: No significant difference (Fail to reject H0)\")\n",
        "\n",
        "# Run function\n",
        "z_test_t_test()\n"
      ],
      "metadata": {
        "id": "xqIp69BI5Q-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def confidence_interval(sample, confidence=0.95):\n",
        "    n = len(sample)  # Sample size\n",
        "    mean = np.mean(sample)  # Sample mean\n",
        "    std_err = stats.sem(sample)  # Standard error of mean (SEM)\n",
        "\n",
        "    # Get t-critical value for given confidence level\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n - 1)\n",
        "\n",
        "    # Compute margin of error\n",
        "    margin_of_error = t_critical * std_err\n",
        "\n",
        "    # Compute confidence interval\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_data = np.random.normal(50, 10, 30)  # Simulated dataset\n",
        "ci = confidence_interval(sample_data)\n",
        "\n",
        "print(f\"95% Confidence Interval: {ci}\")"
      ],
      "metadata": {
        "id": "nlzf0SIG5f-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def margin_of_error(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculates the margin of error for a given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: Array-like, the sample data.\n",
        "    - confidence: Confidence level (default = 0.95 for 95% CI).\n",
        "\n",
        "    Returns:\n",
        "    - Margin of Error (MoE).\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    std_err = stats.sem(sample)  # Standard error of mean (SEM)\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n - 1)  # t-critical value\n",
        "    return t_critical * std_err  # Margin of Error\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(50, 10, 30)  # Simulated dataset\n",
        "moe = margin_of_error(sample_data)\n",
        "\n",
        "print(f\"Margin of Error: {moe:.4f}\")"
      ],
      "metadata": {
        "id": "_d8IIWg45p97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.\n",
        "def bayes_theorem(prior, likelihood, marginal_likelihood):\n",
        "    posterior = (likelihood * prior) / marginal_likelihood\n",
        "    return posterior\n",
        "\n",
        "# Example Usage\n",
        "prior_A = 0.01  # Probability of having a rare disease\n",
        "likelihood_B_given_A = 0.95  # Test sensitivity (True Positive Rate)\n",
        "likelihood_B_given_not_A = 0.05  # False Positive Rate\n",
        "prior_not_A = 1 - prior_A  # Probability of NOT having the disease\n",
        "\n",
        "# Marginal probability of a positive test result\n",
        "marginal_B = (likelihood_B_given_A * prior_A) + (likelihood_B_given_not_A * prior_not_A)\n",
        "\n",
        "# Compute Posterior Probability\n",
        "posterior_A_given_B = bayes_theorem(prior_A, likelihood_B_given_A, marginal_B)\n",
        "\n",
        "print(f\"Posterior Probability: {posterior_A_given_B:.4f}\")  # Probability of having the disease given a positive test\n"
      ],
      "metadata": {
        "id": "VIGGbUSU51to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample contingency table (rows: Category A, columns: Category B)\n",
        "data = np.array([[20, 30],  # Group 1\n",
        "                 [25, 25]]) # Group 2\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(data)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\\n\", expected)\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Variables are dependent (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant association (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "km7rDjvh6A11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed data (contingency table)\n",
        "observed = np.array([[30, 10],\n",
        "                      [20, 40]])\n",
        "\n",
        "# Calculate expected frequencies\n",
        "_, _, _, expected = stats.chi2_contingency(observed)\n",
        "\n",
        "# Print expected frequencies\n",
        "print(\"Expected Frequencies:\\n\", expected)\n"
      ],
      "metadata": {
        "id": "0nEor52q6PRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed data\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected data (assuming equal distribution)\n",
        "expected = np.array([33.3, 33.3, 33.3])\n",
        "\n",
        "# Perform Chi-square Goodness-of-Fit test\n",
        "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Observed distribution significantly differs from expected (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "ct91gQq56erB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate Chi-square distribution with different degrees of freedom (df)\n",
        "df_values = [2, 4, 6, 10]\n",
        "x = np.linspace(0, 30, 1000)\n",
        "\n",
        "# Plot Chi-square distributions\n",
        "plt.figure(figsize=(8, 5))\n",
        "for df in df_values:\n",
        "    plt.plot(x, stats.chi2.pdf(x, df), label=f'df={df}')\n",
        "\n",
        "plt.title(\"Chi-square Distribution\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kGaj89GU6pLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate two random samples\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(50, 10, 30)  # Mean=50, Std=10, Size=30\n",
        "sample2 = np.random.normal(50, 15, 30)  # Mean=50, Std=15, Size=30\n",
        "\n",
        "# Compute sample variances\n",
        "var1 = np.var(sample1, ddof=1)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Perform F-test\n",
        "F_stat = var1 / var2  # Always put larger variance in numerator\n",
        "df1 = len(sample1) - 1\n",
        "df2 = len(sample2) - 1\n",
        "p_value = 2 * (1 - stats.f.cdf(F_stat, df1, df2))  # Two-tailed test\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Variances are significantly different (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference in variances (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "xCGRbr8X6znL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate three random samples (groups)\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "group3 = np.random.normal(60, 10, 30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "F_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference between group means (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference between group means (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "T1dJmN2s68Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate three random groups\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "group3 = np.random.normal(60, 10, 30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "F_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference between group means (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference between group means (Fail to reject H0)\")\n",
        "\n",
        "# Plot the distributions\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title(\"One-Way ANOVA: Group Mean Comparison\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jDov0vRY7F8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    \"\"\"\n",
        "    Checks ANOVA assumptions: normality, independence, and equal variance.\n",
        "\n",
        "    Parameters:\n",
        "    - groups: Multiple groups (lists or NumPy arrays).\n",
        "\n",
        "    Returns:\n",
        "    - Prints test results for normality, independence, and equal variance.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Normality Test (Shapiro-Wilk Test)\n",
        "    print(\"📌 Normality Check (Shapiro-Wilk Test):\")\n",
        "    for i, group in enumerate(groups, 1):\n",
        "        stat, p_value = stats.shapiro(group)\n",
        "        print(f\"Group {i}: W-stat={stat:.4f}, P-value={p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"❗ Group {i} is NOT normally distributed.\")\n",
        "        else:\n",
        "            print(f\"✅ Group {i} is normally distributed.\")\n",
        "\n",
        "    # 2. Independence (Visual Check - Boxplot)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.boxplot(groups, labels=[f'Group {i+1}' for i in range(len(groups))])\n",
        "    plt.title(\"Independence Check: Boxplot of Groups\")\n",
        "    plt.ylabel(\"Values\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Equal Variance Test (Levene’s Test)\n",
        "    print(\"\\n Homogeneity of Variance Check (Levene’s Test):\")\n",
        "    stat, p_value = stats.levene(*groups)\n",
        "    print(f\"Levene’s Test: W-stat={stat:.4f}, P-value={p_value:.4f}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Variances are NOT equal (Violated assumption).\")\n",
        "    else:\n",
        "        print(\"Variances are equal (Assumption holds).\")\n",
        "\n",
        "# Example usage with random data\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "group3 = np.random.normal(60, 10, 30)\n",
        "\n",
        "check_anova_assumptions(group1, group2, group3)\n"
      ],
      "metadata": {
        "id": "_0UhWSxI7OXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulating data\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'Factor_A': np.repeat(['A1', 'A2'], 30),  # First categorical factor\n",
        "    'Factor_B': np.tile(['B1', 'B2', 'B3'], 20),  # Second categorical factor\n",
        "    'Response': np.random.normal(50, 10, 60)  # Continuous response variable\n",
        "})\n",
        "\n",
        "# Perform Two-Way ANOVA\n",
        "model = ols('Response ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Print ANOVA results\n",
        "print(anova_table)\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n Interpretation:\")\n",
        "for factor in [\"C(Factor_A)\", \"C(Factor_B)\", \"C(Factor_A):C(Factor_B)\"]:\n",
        "    p_val = anova_table.loc[factor, \"PR(>F)\"]\n",
        "    if p_val < 0.05:\n",
        "        print(f\"{factor} significantly affects the response (Reject H0)\")\n",
        "    else:\n",
        "        print(f\"{factor} has no significant effect (Fail to reject H0)\")\n",
        "\n",
        "# Visualization of Interaction Effect\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.pointplot(x=\"Factor_A\", y=\"Response\", hue=\"Factor_B\", data=data, dodge=True, markers=[\"o\", \"s\", \"D\"])\n",
        "plt.title(\"Interaction Plot: Factor A & B\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kP1vKRNS7bJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define degrees of freedom for F-distribution\n",
        "df1_values = [1, 5, 10]\n",
        "df2 = 20  # Fixed denominator degrees of freedom\n",
        "x = np.linspace(0, 5, 1000)  # X-axis values\n",
        "\n",
        "# Plot F-distributions for different numerator degrees of freedom\n",
        "plt.figure(figsize=(8, 5))\n",
        "for df1 in df1_values:\n",
        "    plt.plot(x, stats.f.pdf(x, df1, df2), label=f'df1={df1}, df2={df2}')\n",
        "\n",
        "plt.title(\"F-Distribution for Different Degrees of Freedom\")\n",
        "plt.xlabel(\"F-value\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "olBAnoHp7mQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate three random groups\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "group3 = np.random.normal(60, 10, 30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "F_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference between group means (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference between group means (Fail to reject H0)\")\n",
        "\n",
        "# Visualization: Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title(\"One-Way ANOVA: Group Mean Comparison\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PVM3BTTm7uS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate random data from a normal distribution\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(50, 10, 30)  # Mean=50, Std=10, Size=30\n",
        "sample2 = np.random.normal(52, 10, 30)  # Mean=52, Std=10, Size=30\n",
        "\n",
        "# Perform independent t-test (assuming unequal variances)\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2, equal_var=False)\n",
        "\n",
        "# Print results\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Significant difference between means (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference between means (Fail to reject H0)\")\n",
        "\n",
        "# Visualization: Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot([sample1, sample2], labels=['Sample 1', 'Sample 2'])\n",
        "plt.title(\"T-Test: Mean Comparison\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BBRf1gwY75dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate sample data\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(50, 10, 30)  # Mean=50, Std=10, Size=30\n",
        "sample_size = len(sample)\n",
        "sample_variance = np.var(sample, ddof=1)  # Sample variance (unbiased)\n",
        "\n",
        "# Hypothesized population variance\n",
        "pop_variance = 100  # Example hypothesis: σ² = 100\n",
        "\n",
        "# Compute Chi-square statistic\n",
        "chi_square_stat = (sample_size - 1) * sample_variance / pop_variance\n",
        "\n",
        "# Calculate p-value (two-tailed test)\n",
        "p_value = 2 * min(stats.chi2.cdf(chi_square_stat, df=sample_size-1),\n",
        "                   1 - stats.chi2.cdf(chi_square_stat, df=sample_size-1))\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square Statistic: {chi_square_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Significant difference in population variance (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference in population variance (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "LRgN6Tsl8CiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test_proportions(success_a, size_a, success_b, size_b):\n",
        "    \"\"\"\n",
        "    Performs a two-proportion Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - success_a: Number of successes in group A\n",
        "    - size_a: Total sample size in group A\n",
        "    - success_b: Number of successes in group B\n",
        "    - size_b: Total sample size in group B\n",
        "\n",
        "    Returns:\n",
        "    - Z-statistic and P-value\n",
        "    \"\"\"\n",
        "    # Proportions\n",
        "    p1 = success_a / size_a\n",
        "    p2 = success_b / size_b\n",
        "\n",
        "    # Pooled proportion\n",
        "    p_pool = (success_a + success_b) / (size_a + size_b)\n",
        "\n",
        "    # Standard error\n",
        "    se = np.sqrt(p_pool * (1 - p_pool) * (1/size_a + 1/size_b))\n",
        "\n",
        "    # Compute Z-score\n",
        "    z_score = (p1 - p2) / se\n",
        "\n",
        "    # Compute p-value (two-tailed)\n",
        "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "    return z_score, p_value\n",
        "\n",
        "# Example: Comparing conversion rates in A/B testing\n",
        "success_a, size_a = 45, 200  # Group A: 45 successes out of 200\n",
        "success_b, size_b = 30, 180  # Group B: 30 successes out of 180\n",
        "\n",
        "z_stat, p_val = z_test_proportions(success_a, size_a, success_b, size_b)\n",
        "\n",
        "# Print results\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_val < alpha:\n",
        "    print(\"Significant difference between proportions (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference between proportions (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "HCtkzTwQ8MiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate two datasets\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(50, 10, 30)  # Mean=50, Std=10, Size=30\n",
        "group2 = np.random.normal(50, 15, 30)  # Mean=50, Std=15, Size=30\n",
        "\n",
        "# Compute sample variances\n",
        "var1 = np.var(group1, ddof=1)  # Unbiased variance\n",
        "var2 = np.var(group2, ddof=1)\n",
        "\n",
        "# Compute F-statistic\n",
        "F_stat = var1 / var2 if var1 > var2 else var2 / var1\n",
        "df1 = len(group1) - 1\n",
        "df2 = len(group2) - 1\n",
        "\n",
        "# Compute p-value (one-tailed test)\n",
        "p_value = 1 - stats.f.cdf(F_stat, df1, df2)\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Significant difference in variances (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference in variances (Fail to reject H0)\")\n",
        "\n",
        "# Visualization: Boxplot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot([group1, group2], labels=['Group 1', 'Group 2'])\n",
        "plt.title(\"F-Test: Variance Comparison\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wa0RlVJ-8V3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27.\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulated observed data (e.g., survey responses, frequencies)\n",
        "observed = np.array([50, 30, 20])  # Counts in different categories\n",
        "\n",
        "# Expected frequencies (assuming equal distribution)\n",
        "expected = np.array([sum(observed) / len(observed)] * len(observed))\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Significant difference from the expected distribution (Reject H0)\")\n",
        "else:\n",
        "    print(\"No significant difference (Fail to reject H0)\")\n"
      ],
      "metadata": {
        "id": "dB2jSat28jTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Theoritical Answers"
      ],
      "metadata": {
        "id": "oC965Yvt9geT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hypothesis testing in statistics is a method used to determine whether there is enough evidence in a sample to infer a conclusion about a population."
      ],
      "metadata": {
        "id": "ZgTguhvL9kAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\n",
        "  Null Hypothesis (H₀):\n",
        "\n",
        "  Assumes no effect, no difference, or no relationship in the population.\n",
        "\n",
        "  Example: \"The new drug has no effect on blood pressure.\"\n",
        "\n",
        "  Alternative Hypothesis (H₁ or Ha):\n",
        "\n",
        "  Suggests a significant effect, difference, or relationship exists.\n",
        "\n",
        "  Example: \"The new drug significantly lowers blood pressure.\""
      ],
      "metadata": {
        "id": "oHGAbh5x9xEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The significance level (α) is the probability of rejecting the null hypothesis (H₀) when it is actually true (Type I error).\n",
        "\n",
        "  Common Values:\n",
        "\n",
        "  0.05 (5%) → Most commonly used\n",
        "\n",
        "  0.01 (1%) → More strict (for critical tests)\n",
        "\n",
        "  0.10 (10%) → Less strict\n",
        "\n",
        "  Importance:\n",
        "  *  Controls Type I Error (False Positive).\n",
        "  *  Determines Critical Value for rejecting H₀.\n",
        "  *  Lower α → More confidence in rejecting H₀.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rv5FyCyL-Ai5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The P-value is the probability of obtaining the observed results (or more extreme) if the null hypothesis (H₀) is true.\n",
        "\n",
        "  Interpretation:\n",
        "\n",
        "  *   P-value < α (e.g., 0.05) → Reject H₀ (Significant result).\n",
        "\n",
        "  * P-value ≥ α → Fail to reject H₀ (No significant result).  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FZfkrg8g-qMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Interpreting the P-value in Hypothesis Testing:\n",
        "\n",
        "  *   P-value < α (e.g., 0.05) → Reject H₀\n",
        "  \n",
        "      Strong evidence against the null hypothesis → Significant result\n",
        "\n",
        "  *   P-value ≥ α → Fail to reject H₀\n",
        "\n",
        "      Not enough evidence to reject the null hypothesis → No significant result\n",
        "\n"
      ],
      "metadata": {
        "id": "jY4Uc-8l-_Tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Type 1 Error (False Positive):\n",
        "  *   Definition: Rejecting the null hypothesis when it is actually true.\n",
        "\n",
        "  *   Analogy: Like a fire alarm going off when\n",
        "\n",
        "  *   Symbol: α (alpha)\n",
        "\n",
        "  Type 2 Error (False Negative):\n",
        "  *   Definition: Failing to reject the null hypothesis when it is actually false.\n",
        "  *   Analogy: Like a fire alarm not going off when there is a fire. It missed the real event.\n",
        "  *  Symbol: β (beta)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Hv6ne8b_g9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. One-tailed test:\n",
        "  * Direction: Checks for an effect in a specific direction (either greater than or less than).\n",
        "  * Example: Testing if a new drug increases blood pressure.\n",
        "  * Rejection region: Only on one side of the distribution.\n",
        "\n",
        "  Two-tailed test:\n",
        "\n",
        "  * Direction: Checks for an effect in either direction (different from).\n",
        "  * Example: Testing if a new drug has any effect on blood pressure (could be increase or decrease).\n",
        "  * Rejection region: Split between both tails of the distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4RcUXy85AewA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. A Z-test is a statistical test used to determine whether two population means are different when the population standard deviation is known and the sample size is large (n ≥ 30).\n",
        "\n",
        "  When to Use:\n",
        "  * Population standard deviation (σ) is known.\n",
        "  * Sample size is large (n ≥ 30).\n",
        "  * Data follows a normal distribution (or approx. normal for large samples).\n"
      ],
      "metadata": {
        "id": "2x2HVGCZBRt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Z-Score in Hypothesis Testing\n",
        "\n",
        "  Formula:\n",
        "\n",
        "  Z = (sample mean - population mean) / (population standard deviation / √sample size)\n",
        "\n",
        "  * sample mean is the average of your sample data.\n",
        "  * population mean is the average of the entire population (known or assumed).\n",
        "  * population standard deviation is how spread out the population data is (known or assumed).\n",
        "  * sample size is the number of data points in your sample.\n",
        "\n",
        "  Representation in Hypothesis Testing:\n",
        "  \n",
        "  * Measures the difference between your sample mean and the population mean in terms of standard deviations.\n",
        "  * Helps determine how likely it is to observe the sample data if the null hypothesis is true.\n",
        "  * Is used to find the p-value, which ultimately helps you decide whether to reject or fail to reject the null hypothesis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hNsJAyPGB0l4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. T-Distribution:\n",
        "\n",
        "  A probability distribution used in hypothesis testing when the sample size is small (n < 30) and population standard deviation (σ) is unknown.\n",
        "\n",
        "  Similar to the normal distribution but has heavier tails (more variability).\n",
        "\n",
        "  When to Use T-Distribution:\n",
        "\n",
        "  *   Small sample size (n < 30).\n",
        "  *   Unknown population standard deviation (σ).\n",
        "  *   Normally distributed or approximately normal data.\n"
      ],
      "metadata": {
        "id": "OyT7lyT6DfoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Z-test:\n",
        "\n",
        "  Used when the population standard deviation is known and the sample size is large.\n",
        "\n",
        "  Relies on the normal distribution.\n",
        "\n",
        "  T-test:\n",
        "\n",
        "  Used when the population standard deviation is unknown and the sample size is small.\n",
        "  \n",
        "  Relies on the t-distribution, which has heavier tails to account for more uncertainty."
      ],
      "metadata": {
        "id": "tv2VfXWlD4mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. A T-test is a statistical test used to compare the means of one or two groups when the population standard deviation (σ) is unknown, especially for small samples (n < 30).\n",
        "\n",
        "  When to Use:\n",
        "\n",
        "  *  Small sample size (n < 30).\n",
        "  *  Unknown population standard deviation (σ).\n",
        "  *  Normally distributed or approximately normal data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "78K_vYopEKZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Relationship Between Z-Test and T-Test\n",
        "  \n",
        "  1. Both are used for hypothesis testing to compare means.\n",
        "  2. Z-test is used when the sample size is large (n ≥ 30) and population standard deviation (σ) is known.\n",
        "  3. T-test is used when the sample size is small (n < 30) and σ is unknown.\n",
        "  4. As sample size increases (n → ∞), the T-distribution approaches the Z-distribution, making them nearly identical for large samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "bTeJPRD0Ekvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. A confidence interval (CI) is a range of values that estimates the true population parameter with a certain level of confidence (e.g., 95%).\n",
        "\n",
        "  Interpretation:\n",
        "\n",
        "  1.  A 95% CI means we are 95% confident that the true population mean lies within the interval.\n",
        "  2.   If a CI does not include a hypothesized value (e.g., population mean), we may reject H₀ in hypothesis testing.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mvcSFhxmFL4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. The Margin of Error (MoE) represents the maximum expected difference between the sample estimate and the true population value.\n",
        "\n",
        " it Affect the Confidence Interval by:\n",
        "\n",
        "  *   Directly determines the width: A larger margin of error creates a wider interval, indicating more uncertainty.\n",
        "  *  Affected by sample size and confidence level: Larger samples and lower confidence levels result in smaller margins of error and narrower intervals.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0ROgQaCFrmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Bayes' Theorem in Statistics\n",
        "\n",
        "  P(A|B) = [P(B|A) * P(A)] / P(B)\n",
        "\n",
        "  Where:\n",
        "\n",
        "  P(A|B): Posterior probability of event A given evidence B.\n",
        "\n",
        "  P(B|A): Likelihood of evidence B given event A.\n",
        "\n",
        "  P(A): Prior probability of event A.\n",
        "\n",
        "  P(B): Marginal likelihood of evidence B\n",
        "\n",
        "\n",
        "    Significance:\n",
        "\n",
        "  *   Updates probabilities based on new evidence.\n",
        "  *   Used in medical diagnosis, spam filtering, and machine learning.\n",
        "  *   Helps in decision-making under uncertainty.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g9dTtD-9GeTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Definition:\n",
        "  The Chi-square distribution is a probability distribution used for hypothesis testing with categorical data. It is skewed right and depends on degrees of freedom (df).\n",
        "\n",
        "  When It’s Used:\n",
        "\n",
        "  *   Chi-square test for independence → Checks if two categorical variables are related.\n",
        "  *  Chi-square goodness-of-fit test → Tests if\n",
        "  observed data matches an expected distribution.\n",
        "  *   Variance testing → Used in population variance comparisons.\n"
      ],
      "metadata": {
        "id": "EsbglxZAHYbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Definition:\n",
        "\n",
        "  The Chi-square goodness-of-fit test checks whether an observed categorical dataset follows an expected distribution.\n",
        "\n",
        "  Application:\n",
        "\n",
        "  *   Define null hypothesis (H₀): The data follows the expected distribution.\n",
        "  *   Calculate expected frequencies.\n",
        "  *   Compute Chi-square statistic.\n",
        "  *   Compare with the critical value or p-value.\n",
        "  *   Reject H₀ if the difference is significant.\n",
        "\n"
      ],
      "metadata": {
        "id": "WP8JfJECH13T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Definition:\n",
        "\n",
        "  The F-distribution is a right-skewed probability distribution used to compare variances between groups. It depends on two degrees of freedom (df1, df2).\n",
        "\n",
        "  When It’s Used:\n",
        "\n",
        "  *   F-Test for Variance Comparison → Tests if two populations have equal variances.\n",
        "  *   ANOVA (Analysis of Variance) → Compares means across multiple groups by analyzing variance.\n",
        "  *   Regression Analysis → Evaluates the significance of regression models.\n"
      ],
      "metadata": {
        "id": "F6utaoJ-Im4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Definition:\n",
        "\n",
        "  Analysis of Variance (ANOVA) is a statistical test used to compare means across multiple groups to check if they differ significantly.\n",
        "\n",
        "  Key Assumptions:\n",
        "\n",
        "  *   Normality → Data in each group should follow a normal distribution.\n",
        "  *   Independence → Observations must be independent within and between groups.\n",
        "  *   Homogeneity of Variance (Homoscedasticity) → All groups should have equal variances.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qfDXKYiTI_oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Types of ANOVA Tests:\n",
        "\n",
        "  *   One-Way ANOVA → Compares means of one independent variable (factor) across multiple groups.\n",
        "  *   Two-Way ANOVA → Compares means of two independent variables and their interaction effects.\n",
        "  *   Repeated Measures ANOVA → Compares means of the same group measured multiple times.\n",
        "  *   MANOVA (Multivariate ANOVA) → Compares means of multiple dependent variables across groups.\n",
        "\n"
      ],
      "metadata": {
        "id": "oQgNm2moJXnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. The F-test is a statistical test that uses the F-distribution to compare the variances of two or more groups.\n",
        "\n",
        "  The relation with hypothesis testing:\n",
        "\n",
        "*   It's used to test hypotheses about the equality of variances.\n",
        "*   If the F-statistic is large and the p-value is small, we reject the null hypothesis of equal variances, indicating a significant difference.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LxPsh_jXJt4V"
      }
    }
  ]
}